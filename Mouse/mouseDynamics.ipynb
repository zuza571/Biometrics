{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#TODO: SAVE EACH MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Upload dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: dane z gotowymi cechami -> czy próbować robić po swojemu ekstrakcję, skoro juz to zrobili?\n",
    "dataset = pd.read_csv('masterTrain.csv')\n",
    "dataset = dataset.iloc[:, 1:]\n",
    "# 377010 x 34\n",
    "# print(dataset.iloc[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into users and impostors\n",
    "num_classes = len(np.unique(dataset['class']))\n",
    "\n",
    "user = {}\n",
    "impostor = {}\n",
    "X_train_list = []\n",
    "X_test_list = []\n",
    "y_train_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    user[i] = dataset.loc[dataset['class'] == i]\n",
    "    impostor[i] = dataset.loc[dataset['class'] != i]\n",
    "    # scale impostor to the same size as user\n",
    "    impostor[i] = impostor[i].sample(n=len(user[i]))\n",
    "\n",
    "    user[i].loc[:, 'class'] = 0\n",
    "    impostor[i].loc[:, 'class'] = 1\n",
    "\n",
    "    merged_data = pd.concat([user[i], impostor[i]])\n",
    "    \n",
    "    X = merged_data.loc[:, 'mean_x_speed':'numCritPoints']\n",
    "    y = merged_data['class']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "extra_tree_forest = ExtraTreesClassifier(n_estimators = 5, criterion ='entropy', max_features = 30)\n",
    "\n",
    "extra_tree_forest.fit(X, y)\n",
    "\n",
    "feature_importance = extra_tree_forest.feature_importances_\n",
    "\n",
    "feature_importance_normalized = np.std([tree.feature_importances_ for tree in extra_tree_forest.estimators_], axis = 0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(X.columns, feature_importance_normalized)\n",
    "plt.xticks(rotation=70)\n",
    "\n",
    "plt.xlabel('Feature Labels')\n",
    "plt.ylabel('Feature Importances')\n",
    "plt.title('Comparison of different Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.80958071 0.80857565 0.80755154 0.8091256  0.80889801 0.80910669\n",
      " 0.80694475 0.8085946  0.80770327        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  0\n",
      "Best hyperparams: {'n_estimators': 750, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 80, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.8095807068145797\n",
      "Mean Squared Error: 0.16066145793825382\n",
      "R-squared (R2): 0.35735416454918656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84      6591\n",
      "           1       0.85      0.82      0.84      6592\n",
      "\n",
      "    accuracy                           0.84     13183\n",
      "   macro avg       0.84      0.84      0.84     13183\n",
      "weighted avg       0.84      0.84      0.84     13183\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.80998496        nan        nan 0.81110777        nan\n",
      " 0.81024561        nan        nan 0.81024561]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  8\n",
      "Best hyperparams: {'n_estimators': 700, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 70, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.8111077694235588\n",
      "Mean Squared Error: 0.16777608469003127\n",
      "R-squared (R2): 0.32889565692342404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84      6235\n",
      "           1       0.85      0.80      0.83      6234\n",
      "\n",
      "    accuracy                           0.83     12469\n",
      "   macro avg       0.83      0.83      0.83     12469\n",
      "weighted avg       0.83      0.83      0.83     12469\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.81737008 0.8168189  0.81714961        nan 0.81675591\n",
      " 0.81445669 0.81503937        nan 0.81543307]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  1\n",
      "Best hyperparams: {'n_estimators': 850, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 80, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.8173700787401575\n",
      "Mean Squared Error: 0.15614764424288233\n",
      "R-squared (R2): 0.3754094230284707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85      7938\n",
      "           1       0.86      0.82      0.84      7938\n",
      "\n",
      "    accuracy                           0.84     15876\n",
      "   macro avg       0.84      0.84      0.84     15876\n",
      "weighted avg       0.84      0.84      0.84     15876\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.81605624 0.81706137 0.8154881  0.81626016 0.8141042  0.81640585\n",
      "        nan 0.81605621        nan 0.81698852]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  7\n",
      "Best hyperparams: {'n_estimators': 750, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.8170613737980915\n",
      "Mean Squared Error: 0.1554597366274327\n",
      "R-squared (R2): 0.3781610534902692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      8581\n",
      "           1       0.86      0.82      0.84      8581\n",
      "\n",
      "    accuracy                           0.84     17162\n",
      "   macro avg       0.85      0.84      0.84     17162\n",
      "weighted avg       0.85      0.84      0.84     17162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.8116692  0.81171472 0.80887709        nan\n",
      " 0.81109256        nan        nan 0.81088012]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  9\n",
      "Best hyperparams: {'n_estimators': 750, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.8117147192716236\n",
      "Mean Squared Error: 0.16521000242777373\n",
      "R-squared (R2): 0.3391599902889051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      8238\n",
      "           1       0.85      0.81      0.83      8238\n",
      "\n",
      "    accuracy                           0.83     16476\n",
      "   macro avg       0.84      0.83      0.83     16476\n",
      "weighted avg       0.84      0.83      0.83     16476\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.81937747        nan 0.81920711        nan 0.82034853\n",
      " 0.82130259        nan        nan 0.81828711]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  2\n",
      "Best hyperparams: {'n_estimators': 850, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 90, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.8213025917336365\n",
      "Mean Squared Error: 0.1482793867120954\n",
      "R-squared (R2): 0.4068824503974877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      7338\n",
      "           1       0.86      0.83      0.85      7337\n",
      "\n",
      "    accuracy                           0.85     14675\n",
      "   macro avg       0.85      0.85      0.85     14675\n",
      "weighted avg       0.85      0.85      0.85     14675\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.81308386 0.81315663        nan        nan        nan\n",
      "        nan        nan 0.8132901  0.81388461]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  3\n",
      "Best hyperparams: {'n_estimators': 750, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 90, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.8138846135814128\n",
      "Mean Squared Error: 0.1617490051441328\n",
      "R-squared (R2): 0.35300397942346884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84     10303\n",
      "           1       0.87      0.80      0.83     10303\n",
      "\n",
      "    accuracy                           0.84     20606\n",
      "   macro avg       0.84      0.84      0.84     20606\n",
      "weighted avg       0.84      0.84      0.84     20606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.79782985        nan 0.80005078        nan 0.79827403\n",
      " 0.79971765 0.79901961 0.80052671        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  4\n",
      "Best hyperparams: {'n_estimators': 850, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.8005267108978614\n",
      "Mean Squared Error: 0.17772842639593908\n",
      "R-squared (R2): 0.28908629441624367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83      7880\n",
      "           1       0.86      0.77      0.81      7880\n",
      "\n",
      "    accuracy                           0.82     15760\n",
      "   macro avg       0.83      0.82      0.82     15760\n",
      "weighted avg       0.83      0.82      0.82     15760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.82221691 0.81961379        nan 0.82132006        nan 0.81935123\n",
      " 0.82053248        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  6\n",
      "Best hyperparams: {'n_estimators': 750, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 80, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.8222169121448213\n",
      "Mean Squared Error: 0.15740659725260303\n",
      "R-squared (R2): 0.3703736061693724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      5715\n",
      "           1       0.86      0.82      0.84      5714\n",
      "\n",
      "    accuracy                           0.84     11429\n",
      "   macro avg       0.84      0.84      0.84     11429\n",
      "weighted avg       0.84      0.84      0.84     11429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kuba\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.7872313  0.78516264 0.78702249 0.78759189\n",
      "        nan        nan 0.7854853  0.78793349]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  5\n",
      "Best hyperparams: {'n_estimators': 700, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 90, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.7879334862488993\n",
      "Mean Squared Error: 0.18796022166552798\n",
      "R-squared (R2): 0.24815910900520866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.81      6587\n",
      "           1       0.79      0.84      0.82      6586\n",
      "\n",
      "    accuracy                           0.81     13173\n",
      "   macro avg       0.81      0.81      0.81     13173\n",
      "weighted avg       0.81      0.81      0.81     13173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "\n",
    "best_models_random = []\n",
    "\n",
    "hyperparams = {\n",
    "        'n_estimators': [700, 750, 850], #TODO: np.arange(700, 1000, step=50), # tested: 100-500, step=100 -> best 500\n",
    "        'max_depth': [None] + list(np.arange(50, 100, step=10)), # tested: 10-50, step=10\n",
    "        'min_samples_split': [1, 2, 4], #TODO: [2, 4, 6, 8, 10],\n",
    "        'min_samples_leaf': [1], #TODO: [1, 2, 4], \n",
    "        'criterion': ['entropy'], #TODO: ['gini','entropy'],\n",
    "        'max_features': ['sqrt'], #TODO: ['log2', 'sqrt'],\n",
    "        'bootstrap': [False] #TODO: [True, False]\n",
    "    }\n",
    "\n",
    "classes = list(range(num_classes))\n",
    "random.shuffle(classes)\n",
    "random_classes = classes[:]\n",
    "\n",
    "for i in random_classes:\n",
    "    X_train = X_train_list[i]\n",
    "    X_test = X_test_list[i]\n",
    "    y_train = y_train_list[i]\n",
    "    y_test = y_test_list[i]\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    random_search = RandomizedSearchCV(rf, hyperparams, cv=5, scoring='accuracy', n_jobs=-1, n_iter=10)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    print('User ', i)\n",
    "    print('Best hyperparams:', random_search.best_params_)\n",
    "    print('Best score: ', random_search.best_score_)\n",
    "\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_models_random.append(best_model)\n",
    "\n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R-squared (R2): {r2}\")\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  0\n",
      "Best hyperparams: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 70, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 780}\n",
      "Best score:  0.8125391726819478\n",
      "Mean Squared Error: 0.16369566866418872\n",
      "R-squared (R2): 0.34521732157561125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      6591\n",
      "           1       0.85      0.82      0.83      6592\n",
      "\n",
      "    accuracy                           0.84     13183\n",
      "   macro avg       0.84      0.84      0.84     13183\n",
      "weighted avg       0.84      0.84      0.84     13183\n",
      "\n",
      "User  1\n",
      "Best hyperparams: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 70, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 720}\n",
      "Best score:  0.8166456692913385\n",
      "Mean Squared Error: 0.16219450743260266\n",
      "R-squared (R2): 0.35122197026958935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84      7938\n",
      "           1       0.85      0.82      0.83      7938\n",
      "\n",
      "    accuracy                           0.84     15876\n",
      "   macro avg       0.84      0.84      0.84     15876\n",
      "weighted avg       0.84      0.84      0.84     15876\n",
      "\n",
      "User  2\n",
      "Best hyperparams: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 75, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 740}\n",
      "Best score:  0.820416587757026\n",
      "Mean Squared Error: 0.1478023850085179\n",
      "R-squared (R2): 0.40879045722065754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      7337\n",
      "           1       0.87      0.83      0.85      7338\n",
      "\n",
      "    accuracy                           0.85     14675\n",
      "   macro avg       0.85      0.85      0.85     14675\n",
      "weighted avg       0.85      0.85      0.85     14675\n",
      "\n",
      "User  3\n",
      "Best hyperparams: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 740}\n",
      "Best score:  0.8193079779497026\n",
      "Mean Squared Error: 0.1541298650878385\n",
      "R-squared (R2): 0.38348053964864603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85     10303\n",
      "           1       0.88      0.80      0.84     10303\n",
      "\n",
      "    accuracy                           0.85     20606\n",
      "   macro avg       0.85      0.85      0.85     20606\n",
      "weighted avg       0.85      0.85      0.85     20606\n",
      "\n",
      "User  4\n",
      "Best hyperparams: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 85, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 720}\n",
      "Best score:  0.8019544249448074\n",
      "Mean Squared Error: 0.17607868020304568\n",
      "R-squared (R2): 0.2956852791878173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83      7880\n",
      "           1       0.86      0.78      0.81      7880\n",
      "\n",
      "    accuracy                           0.82     15760\n",
      "   macro avg       0.83      0.82      0.82     15760\n",
      "weighted avg       0.83      0.82      0.82     15760\n",
      "\n",
      "User  5\n",
      "Best hyperparams: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 80, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 760}\n",
      "Best score:  0.7884458346121469\n",
      "Mean Squared Error: 0.1897821301146284\n",
      "R-squared (R2): 0.24087147516681018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      6586\n",
      "           1       0.80      0.83      0.81      6587\n",
      "\n",
      "    accuracy                           0.81     13173\n",
      "   macro avg       0.81      0.81      0.81     13173\n",
      "weighted avg       0.81      0.81      0.81     13173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "\n",
    "best_models_grid = []\n",
    "\n",
    "hyperparams = {\n",
    "        'n_estimators': list(np.arange(700, 800, step=20)),\n",
    "        'max_depth': [None] + list(np.arange(70, 90, step=5)),\n",
    "        'min_samples_split': [2],\n",
    "        'min_samples_leaf': [1], \n",
    "        'criterion': ['entropy'],\n",
    "        'max_features': ['sqrt'],\n",
    "        'bootstrap': [False]\n",
    "    }\n",
    "\n",
    "classes = list(range(num_classes))\n",
    "random.shuffle(classes)\n",
    "random_classes = classes[:5]\n",
    "\n",
    "for i in range(random_classes):\n",
    "    X_train = X_train_list[i]\n",
    "    X_test = X_test_list[i]\n",
    "    y_train = y_train_list[i]\n",
    "    y_test = y_test_list[i]\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    grid_search = GridSearchCV(rf, hyperparams, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print('User ', i)\n",
    "    print('Best hyperparams:', grid_search.best_params_)\n",
    "    print('Best score: ', grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models_grid.append(best_model)\n",
    "\n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R-squared (R2): {r2}\")\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  0\n",
      "Mean Squared Error: 0.21603580368656602\n",
      "R-squared (R2): 0.135856780281437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79      6592\n",
      "           1       0.81      0.74      0.77      6591\n",
      "\n",
      "    accuracy                           0.78     13183\n",
      "   macro avg       0.79      0.78      0.78     13183\n",
      "weighted avg       0.79      0.78      0.78     13183\n",
      "\n",
      "User:  1\n",
      "Mean Squared Error: 0.20105820105820105\n",
      "R-squared (R2): 0.1957671957671958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80      7938\n",
      "           1       0.82      0.77      0.79      7938\n",
      "\n",
      "    accuracy                           0.80     15876\n",
      "   macro avg       0.80      0.80      0.80     15876\n",
      "weighted avg       0.80      0.80      0.80     15876\n",
      "\n",
      "User:  2\n",
      "Mean Squared Error: 0.21110732538330493\n",
      "R-squared (R2): 0.15557069454568806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      7337\n",
      "           1       0.81      0.75      0.78      7338\n",
      "\n",
      "    accuracy                           0.79     14675\n",
      "   macro avg       0.79      0.79      0.79     14675\n",
      "weighted avg       0.79      0.79      0.79     14675\n",
      "\n",
      "User:  3\n",
      "Mean Squared Error: 0.20508589731146268\n",
      "R-squared (R2): 0.1796564107541493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.80     10303\n",
      "           1       0.83      0.74      0.78     10303\n",
      "\n",
      "    accuracy                           0.79     20606\n",
      "   macro avg       0.80      0.79      0.79     20606\n",
      "weighted avg       0.80      0.79      0.79     20606\n",
      "\n",
      "User:  4\n",
      "Mean Squared Error: 0.21776649746192894\n",
      "R-squared (R2): 0.12893401015228423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79      7880\n",
      "           1       0.82      0.72      0.77      7880\n",
      "\n",
      "    accuracy                           0.78     15760\n",
      "   macro avg       0.79      0.78      0.78     15760\n",
      "weighted avg       0.79      0.78      0.78     15760\n",
      "\n",
      "User:  5\n",
      "Mean Squared Error: 0.2292568131784711\n",
      "R-squared (R2): 0.08297274200150673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      6586\n",
      "           1       0.77      0.78      0.77      6587\n",
      "\n",
      "    accuracy                           0.77     13173\n",
      "   macro avg       0.77      0.77      0.77     13173\n",
      "weighted avg       0.77      0.77      0.77     13173\n",
      "\n",
      "User:  6\n",
      "Mean Squared Error: 0.19756759121532944\n",
      "R-squared (R2): 0.2097296290886287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      5715\n",
      "           1       0.83      0.77      0.80      5714\n",
      "\n",
      "    accuracy                           0.80     11429\n",
      "   macro avg       0.80      0.80      0.80     11429\n",
      "weighted avg       0.80      0.80      0.80     11429\n",
      "\n",
      "User:  7\n",
      "Mean Squared Error: 0.20819251835450414\n",
      "R-squared (R2): 0.16722992658198343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      8581\n",
      "           1       0.81      0.76      0.78      8581\n",
      "\n",
      "    accuracy                           0.79     17162\n",
      "   macro avg       0.79      0.79      0.79     17162\n",
      "weighted avg       0.79      0.79      0.79     17162\n",
      "\n",
      "User:  8\n",
      "Mean Squared Error: 0.20827652578394418\n",
      "R-squared (R2): 0.16689389150579936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80      6234\n",
      "           1       0.82      0.75      0.78      6235\n",
      "\n",
      "    accuracy                           0.79     12469\n",
      "   macro avg       0.79      0.79      0.79     12469\n",
      "weighted avg       0.79      0.79      0.79     12469\n",
      "\n",
      "User:  9\n",
      "Mean Squared Error: 0.2176499150279194\n",
      "R-squared (R2): 0.12940033988832245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79      8238\n",
      "           1       0.81      0.73      0.77      8238\n",
      "\n",
      "    accuracy                           0.78     16476\n",
      "   macro avg       0.79      0.78      0.78     16476\n",
      "weighted avg       0.79      0.78      0.78     16476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models_rf = {}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    X_train = X_train_list[i]\n",
    "    X_test = X_test_list[i]\n",
    "    y_train = y_train_list[i]\n",
    "    y_test = y_test_list[i]\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    print(\"User: \", i)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R-squared (R2): {r2}\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **K Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import KNeighborsClassifier\n",
    "import random\n",
    "\n",
    "best_models_random = []\n",
    "\n",
    "hyperparams = {\n",
    "        'n_neighbors': list(range(2, 21)),\n",
    "        'leaf_size': list(range(1, 31)),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'p': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "classes = list(range(num_classes))\n",
    "random.shuffle(classes)\n",
    "random_classes = classes[:3]\n",
    "\n",
    "for i in random_classes:\n",
    "    X_train = X_train_list[i]\n",
    "    X_test = X_test_list[i]\n",
    "    y_train = y_train_list[i]\n",
    "    y_test = y_test_list[i]\n",
    "\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    random_search = RandomizedSearchCV(knn, hyperparams, cv=5, scoring='accuracy', n_jobs=-1, n_iter=10)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    print('User ', i)\n",
    "    print('Best hyperparams:', random_search.best_params_)\n",
    "    print('Best score: ', random_search.best_score_)\n",
    "\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_models_random.append(best_model)\n",
    "\n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R-squared (R2): {r2}\")\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_grid = []\n",
    "\n",
    "hyperparams = {\n",
    "    'n_neighbors': list(range(2, 21)),\n",
    "    'leaf_size': list(range(1, 31)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2, 3]\n",
    "}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    X_train = X_train_list[i]\n",
    "    X_test = X_test_list[i]\n",
    "    y_train = y_train_list[i]\n",
    "    y_test = y_test_list[i]\n",
    "\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    grid_search = GridSearchCV(knn, hyperparams, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print('User ', i)\n",
    "    print('Best hyperparams:', grid_search.best_params_)\n",
    "    print('Best score: ', grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models_grid.append(best_model)\n",
    "\n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R-squared (R2): {r2}\")\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models_knn = {}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    X_train = X_train_list[i]\n",
    "    X_test = X_test_list[i]\n",
    "    y_train = y_train_list[i]\n",
    "    y_test = y_test_list[i]\n",
    "\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    predictions = knn.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    print(\"User: \", i)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R-squared (R2): {r2}\")\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "models_nn = {}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    X_train = X_train_list[i]\n",
    "    X_test = X_test_list[i]\n",
    "    y_train = y_train_list[i]\n",
    "    y_test = y_test_list[i]\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=31, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='leaky_relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(51, activation='softmax'))\n",
    "\n",
    "    # metrics=['categorical_accuracy']) #TODO: sprawdzić czy to jest dobre\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=100, verbose=2)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"User: \", i)\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = (predictions > 0.95).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_test, predictions, average='macro')\n",
    "    print(f'F1 Score (Macro): {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
